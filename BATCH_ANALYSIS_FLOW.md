# Batch Document Analysis Flow - AI Lawyer

## Overview
New batch document analysis feature that processes multiple documents through a unified OCR and LLM pipeline, creating a "case" entity with a briefcase icon for multiple documents analyzed together.

## Algorithm Flow

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ BATCH DOCUMENT ANALYSIS FLOW                                    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

1. FILE UPLOAD
   ‚îî‚îÄ> Multiple documents uploaded via API
       ‚Ä¢ Supports: JPG, PNG, PDF, DOCX, TXT
       ‚Ä¢ Max 50GB per file
       ‚Ä¢ Multiple files in single request

2. PARALLEL OCR PROCESSING
   ‚îî‚îÄ> All files processed with OpenAI Vision in parallel batches
       ‚Ä¢ Batch size: 3 concurrent requests (to avoid rate limits)
       ‚Ä¢ Each file converted to base64
       ‚Ä¢ Smart preprocessing (deblurring, noise reduction)
       ‚Ä¢ OCR confidence calculated per file
       ‚Ä¢ Results combined with page markers
       ‚Ä¢ Average confidence calculated across all pages

3. TEXT COMBINATION
   ‚îî‚îÄ> All OCR results merged into single unified text
       === –î–û–ö–£–ú–ï–ù–¢ 1: file1.pdf ===
       [OCR text from file 1]
       
       === –î–û–ö–£–ú–ï–ù–¢ 2: file2.jpg ===
       [OCR text from file 2]
       
       === –î–û–ö–£–ú–ï–ù–¢ 3: file3.png ===
       [OCR text from file 3]

4. UNIFIED LLM ANALYSIS
   ‚îî‚îÄ> Complete combined text sent to LLM as single request
       ‚Ä¢ System role: Legal document analysis specialist
       ‚Ä¢ Model: GPT-4o or configured windexai model
       ‚Ä¢ Max tokens: 6000 (for comprehensive case analysis)
       ‚Ä¢ Response format: JSON
       ‚Ä¢ Temperature: 0.1 (for accuracy)
       
       Analysis includes:
       ‚Ä¢ Risks identified across all documents
       ‚Ä¢ Legal errors and inconsistencies
       ‚Ä¢ Recommendations for actions
       ‚Ä¢ Summary of entire case
       ‚Ä¢ Cross-document references

5. CASE CREATION & STORAGE
   ‚îî‚îÄ> Results saved as unified "batch case"
       ‚Ä¢ Case ID: case_[timestamp]_[random]
       ‚Ä¢ Case name: auto-generated from filenames or user-provided
       ‚Ä¢ Case number: optional user input
       ‚Ä¢ Icon: 'briefcase' (for visual distinction in UI)
       ‚Ä¢ Files count: number of documents analyzed
       ‚Ä¢ OCR metadata: combined statistics
       ‚Ä¢ Analysis result: full LLM output

6. DATABASE STORAGE
   ‚îî‚îÄ> New table: batch_cases
       Fields:
       - id (TEXT PRIMARY KEY)
       - user_id (TEXT)
       - case_name (TEXT)
       - case_number (TEXT, optional)
       - description (TEXT)
       - file_count (INTEGER)
       - file_names (TEXT, JSON array)
       - document_type (TEXT, default 'legal')
       - icon (TEXT, default 'briefcase')
       - ocr_metadata (TEXT, JSON)
       - analysis_result (TEXT, JSON)
       - created_at, updated_at, is_deleted
```

## API Endpoints

### 1. Process Batch Documents with OCR & Analysis
```
POST /api/documents/batch-ocr-analysis
Content-Type: multipart/form-data

Parameters:
- documents: File[] (multiple files)
- userId: string (optional, defaults to '1')
- caseName: string (optional)
- caseNumber: string (optional)
- description: string (optional)
- documentType: string (optional, default 'legal')

Response:
{
  success: true,
  caseId: "case_1234567890_abc123",
  caseName: "Case: doc1.pdf, doc2.jpg, doc3.png",
  totalFiles: 3,
  ocrResult: {
    totalPages: 5,
    confidence: 0.92,
    textLength: 25000
  },
  analysis: {
    summary: "...",
    risks: [...],
    recommendations: [...],
    legalErrors: [...]
  },
  metadata: {
    processedAt: "2025-10-21T13:28:50.000Z",
    processingTime: "45000ms",
    icon: "briefcase"
  }
}
```

### 2. Get Batch Case Details
```
GET /api/documents/batch-cases/:caseId

Response:
{
  success: true,
  data: {
    caseId: "case_...",
    caseName: "Case: ...",
    caseNumber: "...",
    description: "...",
    fileCount: 3,
    fileNames: ["doc1.pdf", "doc2.jpg"],
    documentType: "legal",
    icon: "briefcase",
    ocrMetadata: {...},
    analysis: {...},
    createdAt: "2025-10-21T13:28:50.000Z"
  }
}
```

### 3. List User's Batch Cases
```
GET /api/documents/batch-cases?userId=1&limit=50&offset=0

Response:
{
  success: true,
  data: [
    { caseId: "case_...", caseName: "Case 1", ... },
    { caseId: "case_...", caseName: "Case 2", ... },
    ...
  ],
  count: 5
}
```

## Backend Implementation

### Service: `batchDocumentAnalysisService.js`
Main orchestration service handling the entire flow:

```javascript
processBatchDocuments(files, userId, options)
  ‚îú‚îÄ> Extract file paths from multer objects
  ‚îú‚îÄ> performBatchOCR() - parallel OCR for all files
  ‚îú‚îÄ> Combine all OCR text
  ‚îú‚îÄ> performBatchDocumentAnalysis() - LLM analysis
  ‚îú‚îÄ> saveBatchAnalysisAsCase() - store in database
  ‚îî‚îÄ> Return complete result with metadata

saveBatchAnalysisAsCase(userId, files, ocrResults, llmAnalysis, caseInfo)
  ‚îî‚îÄ> documentStorageService.saveBatchCase()
```

### Service: `enhancedOCRService.js` (existing)
Enhanced with batch support:

```javascript
performBatchOCR(images, documentType)
  ‚îú‚îÄ> Process images in batches of 3 (concurrent limit)
  ‚îú‚îÄ> Each batch: await Promise.all(batch.map(performOCR))
  ‚îú‚îÄ> Combine results with page markers
  ‚îú‚îÄ> Calculate average confidence
  ‚îî‚îÄ> Return combined text + metadata
```

### Service: `advancedDocumentAnalysisService.js` (enhanced)
Existing `performBatchDocumentAnalysis()` used:

```javascript
performBatchDocumentAnalysis(documents)
  ‚îú‚îÄ> Combine all document texts
  ‚îú‚îÄ> Send unified prompt to LLM
  ‚îú‚îÄ> Parse JSON response
  ‚îú‚îÄ> Build comprehensive analysis
  ‚îî‚îÄ> Return structured result
```

### Database: `database.js` (new table)
```sql
CREATE TABLE IF NOT EXISTS batch_cases (
  id TEXT PRIMARY KEY,
  user_id TEXT NOT NULL,
  case_name TEXT NOT NULL,
  case_number TEXT,
  description TEXT,
  file_count INTEGER NOT NULL,
  file_names TEXT NOT NULL, -- JSON array
  document_type TEXT DEFAULT 'legal',
  icon TEXT DEFAULT 'briefcase',
  ocr_metadata TEXT, -- JSON
  analysis_result TEXT, -- JSON
  created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
  updated_at DATETIME DEFAULT CURRENT_TIMESTAMP,
  is_deleted BOOLEAN DEFAULT 0
)

-- Indexes
CREATE INDEX idx_batch_cases_user_id ON batch_cases(user_id)
CREATE INDEX idx_batch_cases_created_at ON batch_cases(created_at)
```

### Storage Service: `documentStorageService.js` (enhanced)
New methods:
```javascript
saveBatchCase(userId, caseData)
getBatchCase(caseId)
listBatchCases(userId, options)
getBatchCaseCount(userId)
```

## Controller: `documentController.js` (new methods)

```javascript
handleBatchOCRAnalysis(req, res)
  ‚îî‚îÄ> Validates files
  ‚îî‚îÄ> Calls batchDocumentAnalysisService.processBatchDocuments()
  ‚îî‚îÄ> Returns complete analysis with case icon

getBatchCase(req, res)
  ‚îî‚îÄ> Retrieves case by ID

listBatchCases(req, res)
  ‚îî‚îÄ> Lists user's batch cases
```

## Routes: `documentRoutes.js` (new endpoints)

```javascript
POST /api/documents/batch-ocr-analysis
  ‚îî‚îÄ> upload.array('documents')
  ‚îî‚îÄ> handleBatchOCRAnalysis

GET /api/documents/batch-cases/:caseId
  ‚îî‚îÄ> getBatchCase

GET /api/documents/batch-cases
  ‚îî‚îÄ> listBatchCases
```

## Performance Characteristics

### Processing Times (estimated)
- **OCR Phase**: ~10-15 seconds per document (parallel)
- **LLM Analysis**: ~5-8 seconds for combined text
- **Database Storage**: ~1-2 seconds
- **Total for 3 documents**: ~20-30 seconds

### Resource Usage
- **Memory**: ~50-100MB (for combined text + API calls)
- **API Calls**:
  - OpenAI Vision: N calls (one per file in batch of 3)
  - WindexAI: 1 call (unified analysis)
- **Database**: ~5-10KB per case (analysis + metadata)

### Scalability
- **Batch size**: 3 concurrent OCR requests (configurable)
- **Rate limiting**: 100ms delay between batches
- **Max files**: Limited by timeout (typically 30-60 seconds per request)
- **Max text size**: 6000 tokens (LLM limit for analysis)

## UI Integration

### Visual Indicators
- **Case Icon**: üß≥ (briefcase) for batch cases
- **Progress Stages**:
  1. üì§ "–ó–∞–≥—Ä—É–∂–∞—é —Ñ–∞–π–ª—ã..."
  2. üîç "–†–∞—Å–ø–æ–∑–Ω–∞—é —Ç–µ–∫—Å—Ç –≤ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ö..."
  3. üß† "–ê–Ω–∞–ª–∏–∑–∏—Ä—É—é –≤—Å–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã –∫–∞–∫ –µ–¥–∏–Ω–æ–µ –¥–µ–ª–æ..."
  4. ‚úÖ "–ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω! –ì–æ—Ç–æ–≤–æ –∫ –ø—Ä–æ—Å–º–æ—Ç—Ä—É."

### Case Display
- Show case name with count of files: "Case: doc1.pdf, doc2.jpg (2 files)"
- Display case number if provided
- Show analysis summary with key risks/recommendations
- List all files included in case
- Show creation date and processing time

## Error Handling

### Common Errors
1. **No files provided**: 400 Bad Request
2. **OCR failed**: Fallback or error return
3. **LLM API error**: 500 Server Error with details
4. **Database error**: 500 Server Error with retry

### Retry Logic
- Transient fetch errors: 3 retries with 1s delay
- OCR failures: Continue with other files
- LLM failures: Return error with partial results

## Future Enhancements

1. **Multi-language support**: Auto-detect language per document
2. **Incremental analysis**: Add documents to existing cases
3. **Case versioning**: Track analysis updates
4. **Custom analysis prompts**: User-defined analysis templates
5. **Real-time streaming**: Stream OCR/LLM results as they complete
6. **Background processing**: Queue large batches for async processing
7. **Case comparison**: Compare multiple cases side-by-side
8. **Export options**: Export case as PDF/DOCX with full analysis
